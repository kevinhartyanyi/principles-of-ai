{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2020 Balázs Pintér \n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 20\n",
    "num_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data, like last time\n",
    "\n",
    "corpus, targets = zip(*[(movie_reviews.raw(fileid), category)\n",
    "                         for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)])\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=num_features)\n",
    "bows = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# convert targets to numbers\n",
    "targets = np.array([0 if target == 'neg' else 1 for target in targets])\n",
    "\n",
    "bows = bows.astype(np.float32)\n",
    "targets = targets.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(bows, targets, test_size=0.1, shuffle=True)\n",
    "\n",
    "# the problem: we have sparse arrays, but neural network need dense arrays!\n",
    "# the solution will be word embeddings, here we just convert to dense arrays\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in TensorFlow 2.0, we can see the tensor instantly (same as eager mode in TensorFlow 1.0)\n",
    "tf.ones((4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also see the results of an operation instantly\n",
    "tf.add(tf.constant([1, 2, 3]), tf.constant([4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[4., 4., 4., 4.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [4., 4., 4., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((4, 4)) + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'W1:0' shape=(5000, 20) dtype=float32, numpy=\n",
       " array([[ 0.01592522, -0.00419015,  0.00619319, ..., -0.00845196,\n",
       "          0.00620717, -0.00735237],\n",
       "        [-0.00192597, -0.01602287,  0.01834721, ...,  0.00972443,\n",
       "          0.00741144, -0.00854362],\n",
       "        [-0.00443492, -0.0035197 , -0.0140771 , ...,  0.0019029 ,\n",
       "         -0.01177116, -0.0007234 ],\n",
       "        ...,\n",
       "        [ 0.00117155,  0.00637321,  0.00346894, ..., -0.01635621,\n",
       "          0.00848693,  0.01190089],\n",
       "        [-0.00217524,  0.00598196, -0.00262365, ...,  0.00253259,\n",
       "         -0.00359229, -0.01129465],\n",
       "        [-0.00057631,  0.00029861,  0.02240941, ...,  0.01077843,\n",
       "          0.00327318, -0.01328602]], dtype=float32)>,\n",
       " <tf.Variable 'b1:0' shape=(5000, 20) dtype=float32, numpy=\n",
       " array([[-0.01260709, -0.00986665,  0.01458601, ...,  0.00301094,\n",
       "         -0.00341765, -0.00124887],\n",
       "        [ 0.00594413, -0.00910233,  0.00886685, ..., -0.00310771,\n",
       "         -0.01121224,  0.00931075],\n",
       "        [-0.00040262, -0.00140321,  0.0075372 , ..., -0.00285098,\n",
       "          0.00889983,  0.00342097],\n",
       "        ...,\n",
       "        [ 0.00272242, -0.00197737,  0.00783048, ..., -0.01455204,\n",
       "         -0.00893887,  0.01521284],\n",
       "        [-0.01585979,  0.00209349, -0.00801034, ...,  0.00468555,\n",
       "         -0.00017368, -0.0018396 ],\n",
       "        [-0.01084927, -0.01125938, -0.03147322, ..., -0.01757292,\n",
       "          0.01145382, -0.00806088]], dtype=float32)>,\n",
       " <tf.Variable 'W2:0' shape=(20, 1) dtype=float32, numpy=\n",
       " array([[ 1.3869266e-04],\n",
       "        [ 5.7619571e-05],\n",
       "        [ 1.8908789e-02],\n",
       "        [-2.3770796e-03],\n",
       "        [-2.8906190e-03],\n",
       "        [-2.0581270e-03],\n",
       "        [-1.5100902e-02],\n",
       "        [-4.8706885e-03],\n",
       "        [-4.8284167e-03],\n",
       "        [-4.6128291e-03],\n",
       "        [ 4.5659617e-03],\n",
       "        [ 1.3097645e-04],\n",
       "        [ 2.0381580e-03],\n",
       "        [ 2.0779020e-03],\n",
       "        [ 1.9360185e-02],\n",
       "        [-8.3394563e-03],\n",
       "        [ 9.1972919e-03],\n",
       "        [-6.1483132e-03],\n",
       "        [ 7.7271846e-04],\n",
       "        [ 1.2218993e-03]], dtype=float32)>,\n",
       " <tf.Variable 'b2:0' shape=(20, 1) dtype=float32, numpy=\n",
       " array([[ 0.00360618],\n",
       "        [ 0.00626449],\n",
       "        [-0.00461118],\n",
       "        [ 0.00293104],\n",
       "        [ 0.00268061],\n",
       "        [-0.00243458],\n",
       "        [-0.01662035],\n",
       "        [ 0.00267809],\n",
       "        [ 0.01356665],\n",
       "        [ 0.0165074 ],\n",
       "        [ 0.009671  ],\n",
       "        [ 0.00224755],\n",
       "        [-0.00589125],\n",
       "        [ 0.0035969 ],\n",
       "        [ 0.00421908],\n",
       "        [-0.00484555],\n",
       "        [-0.00804151],\n",
       "        [-0.00021598],\n",
       "        [-0.00481145],\n",
       "        [-0.00482616]], dtype=float32)>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables are for the parameters (weights) for the NN\n",
    "####### WRONG\n",
    "W1 = tf.Variable(tf.random.normal((num_features, num_neurons), stddev=0.01), name='W1')\n",
    "b1 = tf.Variable(tf.random.normal((num_features, num_neurons), stddev=0.01), name='b1')\n",
    "W2 = tf.Variable(tf.random.normal((num_neurons, 1), stddev=0.01), name='W2')\n",
    "b2 = tf.Variable(tf.random.normal((num_neurons, 1), stddev=0.01), name='b2')\n",
    "W3 = tf.Variable(tf.random.normal((1, num_neurons), stddev=0.01), name='W3')\n",
    "b3 = tf.Variable(tf.random.normal((1, 1), stddev=0.01), name='b3')\n",
    "W1, b1, W2, b2\n",
    "####### WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network itself\n",
    "def forward_pass(X):\n",
    "    z = tf.add(tf.matmul(W1, X), b1)\n",
    "    a = tf.nn.relu(z)\n",
    "    z = tf.add(tf.matmul(W2, a), b2)\n",
    "    a = tf.nn.relu(z)\n",
    "    z = tf.add(tf.matmul(W3, a), b3)\n",
    "    #a = tf.nn.sigmoid(z) # already in loss function\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "def loss(a, y):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=a, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatches(X, y, minibatch_size):\n",
    "\n",
    "# shuffling    \n",
    "    perm = np.random.permutation(X.shape[0])\n",
    "    X_shuffled = X[perm]\n",
    "    y_shuffled = y[perm]\n",
    "    \n",
    "    mini_batches = [(X_shuffled[i*minibatch_size:(i+1)*minibatch_size], y_shuffled[i*minibatch_size:(i+1)*minibatch_size])\n",
    "                   for i in range(X_shuffled.shape[0] // minibatch_size)]\n",
    "# we lost some examples at the end, doesn't really matter for this example\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{11} := w_{11} - lr*\\frac{loss}{\\delta w_{11}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [5000,20], In[1]: [5000,32] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-879c769da674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# important: we have to transpose here! each example is in a column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmini_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-b744f6146841>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the network itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataS/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataS/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   3251\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m       return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3254\u001b[0m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataS/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5622\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5623\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5624\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5625\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5626\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataS/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dataS/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [5000,20], In[1]: [5000,32] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "minibatch_size = 32\n",
    "for epoch in range(num_epochs):\n",
    "# minibatch training\n",
    "    epoch_loss = 0\n",
    "    num_minibatches = X_train.shape[0] // minibatch_size\n",
    "    for X_mini, y_mini in minibatches(X_train, y_train, minibatch_size):\n",
    "# we use a GradientTape to record the gradient for each minibatch\n",
    "        with tf.GradientTape() as t:\n",
    "            # important: we have to transpose here! each example is in a column\n",
    "            mini_loss = loss(forward_pass(X_mini.T), y_mini[None, :])            \n",
    "        # update the weights\n",
    "        dW1, db1, dW2, db2, dW3, db3 = t.gradient(mini_loss, [W1, b1, W2, b2, W3, b3])\n",
    "        W1.assign_sub(learning_rate * dW1)\n",
    "        b1.assign_sub(learning_rate * db1)\n",
    "        W2.assign_sub(learning_rate * dW2)\n",
    "        b2.assign_sub(learning_rate * db2)\n",
    "        W3.assign_sub(learning_rate * dW3)\n",
    "        b3.assign_sub(learning_rate * db3)\n",
    "        epoch_loss += mini_loss\n",
    "    epoch_loss /= num_minibatches\n",
    "    predictions = forward_pass(X_train.T)\n",
    "    predictions = np.array([0 if pred < 0 else 1 for pred in tf.squeeze(predictions)])\n",
    "    accuracy = (y_train == predictions).sum() / len(y_train)\n",
    "    print(\"Loss in epoch {}: {}, accuracy: {}\".format(epoch, epoch_loss, accuracy))\n",
    "# accuracy on test set\n",
    "predictions = forward_pass(X_test.T)\n",
    "predictions = np.array([0 if pred < 0 else 1 for pred in tf.squeeze(predictions)])\n",
    "accuracy = (y_test == predictions).sum() / len(y_test)\n",
    "print(\"Accuracy on test set: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
